\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{minted}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[labelformat=simple]{caption}

%https://tex.stackexchange.com/questions/113459/ieeetran-caption-question
%IEEETran doesn't like subcaption
\makeatletter
\let\MYcaption\@makecaption
\makeatother

\usepackage{subcaption}

\makeatletter
\let\@makecaption\MYcaption
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{PAVE: An In Situ Framework for Scientific Visualization and Machine Learning Coupling\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Samuel Leventhal}
\IEEEauthorblockA{\textit{University of Utah School of Computing} \\
\textit{Scientific Computing and Imaging Institute}\\
Salt Lake City, UT., USA \\
samlev@cs.utah.edu}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Mark Kim}
\IEEEauthorblockA{\textit{Oak Ridge National Laboratory} \\
Oak Ridge TN., USA \\
kimmb@ornl.gov}
\and
\IEEEauthorblockN{3\textsuperscript{rd} David Pugmire}
\IEEEauthorblockA{\textit{Oak Ridge National Laboratory} \\
Oak Ridge TN., USA \\
pugmire@ornl.gov}
}

\maketitle

\begin{abstract}
    Machine learning (ML) has emerged as a tool for understanding data at scale. However, this new methodology comes at a cost because ML requires the use of even more HPC resources to generate ML algorithms. In addition to the compute resources required to develop ML algorithms, ML does not side step one of the biggest challenges on leading-edge HPC systems: the increasing gap between compute performance and I/O bandwidth. This has led to a strong push towards \textit{in situ}, processing the data as it is generated, strategies to mitigate the I/O bottleneck. Unfortunately, there are no \textit{in situ} frameworks dedicated to coupling scientific visualization and ML at scale to develop ML algorithms for scientific visualization.
    
    To address the ML and \textit{in situ} visualization gap, we introduce PAVE. PAVE is an \textit{in situ} framework which addresses the data management needs between visualisation and machine learning tasks. We demonstrate our framework with a case study that accelerates physically-based light rendering, path-tracing, through the use of a conditional Generative Adversarial neural Network (cGAN). PAVE couples the training over path-traced images resulting in a generative model able to produce scene renderings with accurate light transport and global illumination of a quality comparable to offline approaches in a more efficient manner.
    
\end{abstract}

\begin{IEEEkeywords}
    VTKm, neural networks, generative adversarial network, in situ, PyTorch, path-tracing
\end{IEEEkeywords}

\newcommand{\markcomment}[1]{\textcolor{red}{#1}}

% \begin{teaserfigure}
%     \includegraphics[width=\textwidth]{buffer_results_teaser.png}
%     \caption{\textmd{Rendered Conditional Geometry Buffers ({\bf left set}) and artificial rendering with conditional generative adversarial neural network ({\bf right couple}) comparing ground truth path traced rendering ({\bf left}) with image generated ({\bf right}).}}
%     \Description{Conditional Buffers and path traced rendered with VTKm to be used for training a PyTorch conditional generative adversarial network.}
%     \label{teaser}
%   \end{teaserfigure}
\input{Intro.tex}

\input{RelatedWorks.tex}
\input{PAVE.tex}
\input{CaseStudy1.tex}




\section{Cornell Box Experiment}

To evaluate the quality of \textit{in situ} deep learning aided visualisations train the cGAN networks on rendered images of a Cornell box, a commonly used 3D modelling framework for quality assessment. We train the model using renderings of the Cornell box with high light sample count and depth computation per ray for various camera angle perspectives into the box along with the associated image geometry buffers for a given camera orientation. We then assess the quality of the models final generated renderings looking at the accuracy of global illumination. We then also demonstrate the performance of the models ability to render global illumination when given image buffers for a novel scene not used for training similar in content but not exact. The scene used for training is comprised of the classic set up with one overhead light source in the center of a white ceiling, a white back wall and a white floor. The remaining walls are then colored red on the left and green on the right in order to afford different colored light transport and demonstrate diffuse interreflection. The contents of the Cornell box are three cuboids of various shapes and sizes to provide diverse shading and diffused lighting. 

%\vspace{-1.5em}
\begin{figure}
\centering
\begin{subfigure}{0.25\textwidth}
\centering
\includegraphics[width=.9\textwidth]{sc-1080-d-45.png}
\caption{Path traced global illumination rendered}
\end{subfigure}%
\begin{subfigure}{.25\textwidth}
\centering
\includegraphics[width=.9\textwidth]{conditionals.png}
\caption{Geometry buffers}
\label{Gbuf}
\end{subfigure}
\caption{ (a) \textmd{Ground truth image rendered with VTK-m used for training.} (b) \textmd{Global illumination geometry buffers used as conditional variables for generative model. {\bf Top:} left, Albedo. right, Direct Lighting. {\bf Bottom:} left, Normals. right, Depth.}}
\end{figure}
%\vspace{-1em}

The conditional differed shading geometry buffers used are direct lighting, normal planes, depth and albedo as shown in figure \ref{teaser}.

\begin{figure}


\end{figure}

The geometry buffers serve as joint variables for the conditional probability distribution which the global illumination path traced images are considered to exist. The conditional arguments in this experiment then aid the cGAN in learning behavior of light paths given the geometry of a scene in question. 

\input{Results.tex}
\input{Conclusion.tex}
%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\section*{Acknowledgment}
 This research was supported in part by an appointment to the Oak Ridge National Laboratory ASTRO Program, sponsored by the U.S. Department of Energy and administered by the Oak Ridge Institute for Science and Education.



\bibliographystyle{IEEEtran}
\bibliography{pave_ref}
\vspace{12pt}

\end{document}
